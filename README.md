# LLM Knowledge-Retriever with web scraping: Web - Wikipedia - SerpAPI

A multi-source retrieval system that allows users to ask questions and get answers from various sources:

--> **Direct Website Scraping using HTMLLoader**

--> **Wikipedia Search & Retrieval**

--> **Search Engine Results via SerpAPI**

--> The retrieved content is passed to a Large Language Model (LLM) for analysis and answer generation.


Code will be added ...

Note: this repo is still under construction, and I will add its relevant code and complete its README.md file. My task in this project is to 1) get the query from user, 2) search through three main resources (Web (by getting its HTML information and work on its core infor), Wikipedia (by searching through it with its package and getting text information), and SerpAPI (by sending our request to the google and receive information), 3) saving data in local databases such as MySQL, FAISS, or other dabases, and 4) retrieve information for an LLM to generate response to the audience.
